<!DOCTYPE html>

<html>
<head>
	<!-- <meta name="yandex-verification" content="a2b0dfa3a10b5338" /> -->
	<meta charset="utf-8" />
	<title>Yichen (Zach) Wang</title>
	<link rel="stylesheet" href="style.css" />

	<link href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,400,700" rel="stylesheet">

	<script>
	    function unhide(divID) {
	        var item = document.getElementById(divID);
	        if (item) {
	            item.className=(item.className=='hidden')?'unhidden':'hidden';
	        }
	}
	</script>

    <!-- 

	<script type="text/javascript">
		var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
		document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
	</script>	 -->
	
	
    <link rel="icon" href="UChicago_Shield.png" />
    <meta name="author" content="Yichen Wang">
    <meta name="keywords" content="Yichen Wang Zach UChicago XJTU NLP UW UC Berkeley interaction generation detection evaluation planning large language model alignment RLHF natural language processing artificial intelligence machine learning">
    <meta name="robots" content="index,follow">
    <meta name="description" content="Homepage of Yichen Wang (Zach) UChicago & XJTU NLP.">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

    <script defer src="https://eu.umami.is/script.js" data-website-id="6467ba72-ae93-4acc-ad3e-acea51fb88f8"></script>
</head>

<body>
    <div class="wrapper">
    
        <div class="posts-wrapper">
            <div class="post">
                <header>
                <h1>Yichen (Zach) Wang &nbsp <span style="font-family: 'ä»¿å®‹'; font-size: smaller; font-weight: lighter;">çŽ‹å¥•è¾°</span> </h1>
                </header>
                <h2>
                yichenwg at gmail dot com
                <!-- yichenzw at uchicago dot edu  -->
                </h2>
                <nav>
                <h2> <a href="https://scholar.google.com/citations?user=86XiOcsAAAAJ&hl=en" target="_blank"> Google Scholar </a> // <a href="https://www.semanticscholar.org/author/Yichen-Wang/2125062703" target="_blank"> Semantic Scholar </a>// <a href="https://twitter.com/YichenZW" target="_blank"> Twitter </a> // <a href="https://github.com/YichenZW" target="_blank">GitHub</a> //  
                    <a href="#.pdf" download>
                        Curriculum Vitae
                    </a></h2>
                </nav>
                <br>
                <br>
                <main>
                <p>
                <img src='me.jpg' style="float:right; width:300px;"/>
                I am an incoming Ph.D. student at the University of Chicago to be advised by Prof. <a href="https://minalee.info/" target="_blank">Mina Lee</a> and Prof. <a href="https://ariholtzman.com/" target="_blank">Ari Holtzman</a>, within <a href="https://ci.cs.uchicago.edu/" target="_blank">UChicago C&I</a>.
                I am broadly interested in human-LLM interaction on evaluation and generation,  LLM safety (i.e., machine-generated text detection, watermarking, and stress testing), planning in controlled generation, and alignment anlaysis.
                <br> <br>
                Currently, I am an undergrad at Xiâ€™an Jiaotong University (XJTU) in the CS Honors Program, mentored by Prof. <a href="https://gr.xjtu.edu.cn/en/web/xm.liu/home" target="_blank">Xiaoming Liu</a> and Prof. <a href="https://gr.xjtu.edu.cn/en/web/cshen/english" target="_blank">Chao Shen</a>. Iâ€™ll be graduating at the end of June 2024. I am also interning at <a href="https://www.cs.washington.edu/research/nlp/" target="_blank">UW NLP</a> (now remote), working with Dr. <a href="https://cloudygoose.github.io/" target="_blank">Tianxing He</a> and Prof. <a href="https://homes.cs.washington.edu/~yuliats/" target="_blank">Yulia Tsvetkov</a>. And I stay in close contact with Prof. <a href="https://gr.xjtu.edu.cn/en/web/minnluo" target="_blank">Minnan Luo</a> and the <a href="https://luoundergradxjtu.github.io/index.html" target="_blank">LUD Lab</a>. I was at UC Berkeley as a visiting student in 2023, working with Dr. <a href="https://yangkevin2.github.io/" target="_blank">Kevin Yang</a> and Prof. <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a> within <a href="http://nlp.cs.berkeley.edu/" target="_blank">Berkeley NLP</a>. 
                </p>
                </main>
                <br>
            </div>
        </div>

        <div class="posts-wrapper" style="clear:both">
            <h3 style="margin-bottom:0.75em;">news</h3>
            <div class="news">
                <p>
                    <u>Apr. 16, 2024</u>: ðŸ†• Here marks the end of my application season. My sincerest thanks to all who helped and supported me -- families, friends, advisors, mentors, faculties (especially those I applied to), and mates. I'm super excited for my new journey!
                    <br>
                    <u>Mar. 24, 2024</u>: SemStamp, the semantic watermark, is now accepted by NAACL24! Fantastic work by <a href="https://nlp4policy.notion.site/Abe-Hou-21661aa32a7a4d19a45b5bf31c11a99e" target="_blank">Abe</a>, and he is seeking a PhD chance in Fall 25. Please consider him! 
                    <br>
                    <u>Dec. 11, 2023</u>: Happy to share that AAAI24 accepts our paper DP2O on prompt optimization!
                    <br>
                    <u>Oct. 10, 2023</u>: Two papers accepted by EMNLP23! All applause and thanks to my co-authors! And I'll be in Singapore on Dec.!
                    <br>
                    <u>Sep. 19, 2023</u>: Today is the date of birth of my academic webpage! Working towards the application season!
                </p>                
            </div>
            <br> 
        </div>

        <!-- <a href="http://ericswallace.com/positive-movies.html"> <font color="white">Positive</font>
     </a>
        <a href="http://ericswallace.com/negative-movies.html"> <font color="white">Negative</font> </a> -->
    
        <div class="posts-wrapper" style="clear:both">
            <h3 style="margin-bottom:0.75em;">publications</h3>
            </i>
            <p>
            <main>
            <ul class="pubs">
                <li>        
                    <a href="http://arxiv.org/abs/2402.11638" target="_blank"><b>Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks</b></a><br>
                    <u>Yichen Wang</u>, Shangbin Feng, Abe Bohan Hou, Xiao Pu, Chao Shen, Xiaoming Liu, Yulia Tsvetkov, and Tianxing He <br>
                    <i>Preprint arxiv:2402</i><br>
                    We comprehensively study the robustness of popular machine-generated text detectors under attacks from diverse categories: editing, paraphrasing, prompting, and co-generating. Our experiments reveal that all detectors exhibit different loopholes. Further, we investigate the reasons behind these defects and propose initial out-of-the-box patches.
                    <br> <a href="javascript:unhide('stumbling24');">Citation</a> // <a href="https://github.com/YichenZW/Robust-Det">Code</a> // <a href="">Dataset</a>
                    <div id="stumbling24" class="hidden">
                        <pre>
@article{wang2024stumbling,
    title={Stumbling Blocks: Stress Testing the Robustness of Machine-Generated Text Detectors Under Attacks},
    author={Wang, Yichen and Feng, Shangbin and Hou, Abe Bohan and Pu, Xiao and Shen, Chao and Liu, Xiaoming and Tsvetkov, Yulia and He, Tianxing},
    journal={arXiv preprint arXiv:2402.11638},
    year={2024}
}</pre>
                    </div>
                </li> 
                <li>        
                    <a href="https://arxiv.org/abs/2402.11399" target="_blank">k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text</a><br>
                    Abe Bohan Hou, Jingyu Zhang, <u>Yichen Wang</u>, Daniel Khashabi, and Tianxing He <br>
                    <i>Preprint arxiv:2402</i><br>
                    We propose k-SemStamp, a simple yet effective enhancement of SemStamp, utilizing k-means clustering as an alternative of LSH to partition the embedding space with awareness of inherent semantic structure.
                    <br> <a href="javascript:unhide('k24');">Citation</a>
                    <div id="k24" class="hidden">
                        <pre>
@article{hou2024k,
    title={k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text},
    author={Hou, Abe Bohan and Zhang, Jingyu and Wang, Yichen and Khashabi, Daniel and He, Tianxing},
    journal={arXiv preprint arXiv:2402.11399},
    year={2024}
}</pre>
                    </div>
                </li> 
                <li>        
                    <a href="https://arxiv.org/abs/2402.00263" target="_blank">Does DetectGPT Fully Utilize Perturbation? Bridging Selective Perturbation to Fine-tuned Contrastive Learning Detector would be Better</a><br>
                    Shengchao Liu, Xiaoming Liu, <u>Yichen Wang</u>, Zehua Cheng, Chengzhengxu Li, Zhaohan Zhang, Yu Lan, and Chao Shen <br>
                    <i>Preprint arxiv:2402</i><br>
                    We propose a novel fine-tuned machine-generated text detector, Pecola, bridging metric-based and fine-tuned methods by contrastive learning on selective perturbation further than DetectGPT.
                    <br> <a href="javascript:unhide('does24');">Citation</a>
                    <div id="does24" class="hidden">
                        <pre>
@article{liu2024does,
    title={Does$\backslash$textsc $\{$DetectGPT$\}$ Fully Utilize Perturbation? Selective Perturbation on Model-Based Contrastive Learning Detector would be Better},
    author={Liu, Shengchao and Liu, Xiaoming and Wang, Yichen and Cheng, Zehua and Li, Chengzhengxu and Zhang, Zhaohan and Lan, Yu and Shen, Chao},
    journal={arXiv preprint arXiv:2402.00263},
    year={2024}
}</pre>
                    </div>
                </li>
                <li>        
                    <a href="https://arxiv.org/abs/2310.03991" target="_blank">SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation</a><br>
                    Abe Bohan Hou, Jingyu Zhang, Tianxing He, <u>Yichen Wang</u>, Yung-Sung Chuang, Hongwei Wang, Lingfeng Shen, Benjamin Van Durme, Daniel Khashabi, and Yulia Tsvetkov<br>
                    <i>NAACL 2024</i><br>
                    Existing watermarking algorithms are vulnerable to paraphrase attacks because of their token-level design. To address this issue, we propose SemStamp, a robust sentence-level semantic watermarking algorithm based on locality-sensitive hashing (LSH), which partitions the semantic space of sentences.
                    <br> <a href="javascript:unhide('semstamp23');">Citation</a>
                    <div id="semstamp23" class="hidden">
                        <pre>
@article{hou2023semstamp,
    title={Semstamp: A semantic watermark with paraphrastic robustness for text generation},
    author={Hou, Abe Bohan and Zhang, Jingyu and He, Tianxing and Wang, Yichen and Chuang, Yung-Sung and Wang, Hongwei and Shen, Lingfeng and Van Durme, Benjamin and Khashabi, Daniel and Tsvetkov, Yulia},
    journal={arXiv preprint arXiv:2310.03991},
    year={2023}
}</pre>
                    </div>
                </li>
                <li>        
                    <a href="https://arxiv.org/abs/2308.07272" target="_blank">Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt Optimization for Few-shot Learning</a><br>Chengzhengxu Li, Xiaoming Liu, <u>Yichen Wang</u>, Duyi Li, Yu Lan, and Chao Shen<br>
                    <i>AAAI 2024</i><br>
                    We propose a dialogue-comprised policy-gradient-based discrete prompt optimization (DP2O) method with dialogue prompt alignment and reinforcement learning to efficiently and effectively generate prompt demonstrations. 
                    <br> <a href="javascript:unhide('dialogue23');">Citation</a>
                    <div id="dialogue23" class="hidden">
                        <pre>
@inproceedings{li2024dialogue,
    title={Dialogue for Prompting: A Policy-Gradient-Based Discrete Prompt Generation for Few-Shot Learning},
    author={Li, Chengzhengxu and Liu, Xiaoming and Wang, Yichen and Li, Duyi and Lan, Yu and Shen, Chao},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    volume={38},
    number={16},
    pages={18481--18489},
    year={2024}
}</pre>
                    </div>
                </li>
                <li>        
                    <a href="https://arxiv.org/abs/2311.04459" target="_blank"><b>Improving Pacing in Long-Form Story Planning</b></a><br><u>Yichen Wang</u>, Kevin Yang, Xiaoming Liu, and Dan Klein<br>
                    <i>EMNLP 2023 Findings</i><br>
                    Existing LLM-based systems for writing long-form stories or story outlines frequently suffer from unnatural pacing, resulting in a jarring experience for the reader. We propose a Concrete Outline Control (CONCOCT) system to improve pacing when automatically generating story outlines. Compared to a baseline hierarchical outline generator, humans judge CONCOCTâ€™s pacing to be more consistent over 57% of the time across multiple outline lengths, and the gains also translate to downstream stories.
                    <br> <a href="javascript:unhide('improving23');">Citation</a> // <a href="https://github.com/YichenZW/Pacing">Code</a> // <a href="https://huggingface.co/datasets/ZachW/GPT-BookSum">Dataset</a> // <a href="#">Poster</a>
                    <div id="improving23" class="hidden"> 
                        <pre>
@inproceedings{wang2023improving,
    title={Improving Pacing in Long-Form Story Planning},
    author={Wang, Yichen and Yang, Kevin and Liu, Xiaoming and Klein, Dan},
    booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
    pages={10788--10845},
    year={2023}
}</pre>
                    </div>
                </li>
                <li>        
                    <a href="https://arxiv.org/abs/2212.10341" target="_blank"><b>CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data Limitation With Contrastive Learning</b></a><br>Xiaoming Liu<sup>=</sup>, Zhaohan Zhang<sup>=</sup>, <u>Yichen Wang<sup>=</sup></u>, Hang Pu, Yu Lan, and Chao Shen<br>
                    <i>EMNLP 2023</i><br>
                    We present a coherence-based contrastive learning model
named CoCo to detect the possible machine-generated texts (MGTs) under the low-resource scenario. We encode coherence information in the form of graph into the text representation and employ an improved contrastive learning framework. Our approach outperforms the state-of-the-art methods at least 1.23%. Also, we surprisingly find that MGTs originated from up-to-date language models could be easier to detect than these from previous models, in our experiments, and we propose some preliminary explanations. 
                    <br> <a href="javascript:unhide('coco2022');">Citation</a> // <a href="https://github.com/YichenZW/Coh-MGT-Detection">Code</a> // <a href="https://huggingface.co/datasets/ZachW/MGTDetect_CoCo">Dataset</a> // <a href="#">Poster</a>
                    <div id="coco2022" class="hidden">
                        <pre>
@inproceedings{liu2023coco,
    title={Coco: Coherence-enhanced machine-generated text detection under low resource with contrastive learning},
    author={Liu, Xiaoming and Zhang, Zhaohan and Wang, Yichen and Pu, Hang and Lan, Yu and Shen, Chao},
    booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
    pages={16167--16188},
    year={2023}
}</pre>
                    </div>
                </li>
        </ul>	 
        <br>
        </main> 
        </p>            
            <footer>
            <p>Thanks <a href="https://yangkevin2.github.io/">Kevin</a>, <a href="https://people.cs.umass.edu/~miyyer/">Mohit</a> and <a href="http://www.ericswallace.com/">Eric</a> for the website template.</p> 
            </footer>
            
    </div>
    </div>
    
</body>
</html>